{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Data Collection and Preprocessing\n",
    "\n",
    "## Customer Experience Analytics for Ethiopian Fintech Apps\n",
    "\n",
    "**Objective:** Scrape and preprocess user reviews from Google Play Store for three Ethiopian banks:\n",
    "- Commercial Bank of Ethiopia (CBE)\n",
    "- Bank of Abyssinia (BOA)\n",
    "- Dashen Bank\n",
    "\n",
    "**Target:** 400+ reviews per bank (1,200 total minimum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add src directory to path for imports\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('../src'))\n",
    "\n",
    "# Standard imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Project imports\n",
    "from config import APP_IDS, BANK_NAMES, DATA_PATHS\n",
    "from scraper import PlayStoreScraper\n",
    "from preprocessing import ReviewPreprocessor\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('Set2')\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration Overview\n",
    "\n",
    "Let's verify our target banks and app IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display target banks\n",
    "print(\"Target Banks for Analysis\")\n",
    "print(\"=\" * 50)\n",
    "for code, name in BANK_NAMES.items():\n",
    "    app_id = APP_IDS[code]\n",
    "    print(f\"\\n{code}: {name}\")\n",
    "    print(f\"   App ID: {app_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Collection - Scraping Google Play Reviews\n",
    "\n",
    "We'll use the `google-play-scraper` library to collect reviews from the Google Play Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the scraper\n",
    "scraper = PlayStoreScraper()\n",
    "\n",
    "# Scrape reviews for all banks\n",
    "# This will collect 400+ reviews per bank\n",
    "raw_df = scraper.scrape_all_banks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display scraping results summary\n",
    "if not raw_df.empty:\n",
    "    print(\"\\nRaw Data Summary\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Total reviews collected: {len(raw_df)}\")\n",
    "    print(f\"\\nReviews per bank:\")\n",
    "    print(raw_df['bank_name'].value_counts())\n",
    "    print(f\"\\nColumns: {list(raw_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview raw data\n",
    "raw_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing\n",
    "\n",
    "The preprocessing pipeline performs:\n",
    "1. Missing data check\n",
    "2. Duplicate removal\n",
    "3. Missing value handling\n",
    "4. Date normalization (YYYY-MM-DD)\n",
    "5. Text cleaning\n",
    "6. English language filtering\n",
    "7. Rating validation (1-5)\n",
    "8. Final output preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and run preprocessor\n",
    "preprocessor = ReviewPreprocessor()\n",
    "success = preprocessor.process()\n",
    "\n",
    "if success:\n",
    "    processed_df = preprocessor.df\n",
    "    print(f\"\\nProcessed dataset shape: {processed_df.shape}\")\n",
    "else:\n",
    "    print(\"Preprocessing failed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data (in case running from saved file)\n",
    "processed_df = pd.read_csv(DATA_PATHS['processed_reviews'])\n",
    "print(f\"Loaded {len(processed_df)} processed reviews\")\n",
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality metrics\n",
    "print(\"Data Quality Report\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nTotal records: {len(processed_df)}\")\n",
    "print(f\"Missing values: {processed_df.isnull().sum().sum()}\")\n",
    "print(f\"Duplicate rows: {processed_df.duplicated().sum()}\")\n",
    "\n",
    "# Check if we meet the minimum requirement\n",
    "min_required = 400\n",
    "print(f\"\\nReviews per bank (minimum required: {min_required}):\")\n",
    "bank_counts = processed_df['bank_name'].value_counts()\n",
    "for bank, count in bank_counts.items():\n",
    "    status = \"✓\" if count >= min_required else \"✗\"\n",
    "    print(f\"  {status} {bank}: {count}\")\n",
    "\n",
    "total_required = 1200\n",
    "total_status = \"✓\" if len(processed_df) >= total_required else \"✗\"\n",
    "print(f\"\\n{total_status} Total reviews: {len(processed_df)} (required: {total_required})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types and info\n",
    "print(\"Dataset Info\")\n",
    "print(\"=\" * 50)\n",
    "processed_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Reviews Distribution by Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "bank_counts = processed_df['bank_name'].value_counts()\n",
    "colors = sns.color_palette('Set2', len(bank_counts))\n",
    "\n",
    "bars = ax.bar(bank_counts.index, bank_counts.values, color=colors, edgecolor='black')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, count in zip(bars, bank_counts.values):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 5, \n",
    "            str(count), ha='center', va='bottom', fontweight='bold', fontsize=12)\n",
    "\n",
    "# Add minimum threshold line\n",
    "ax.axhline(y=400, color='red', linestyle='--', linewidth=2, label='Minimum Required (400)')\n",
    "\n",
    "ax.set_xlabel('Bank', fontsize=12)\n",
    "ax.set_ylabel('Number of Reviews', fontsize=12)\n",
    "ax.set_title('Reviews Collected per Bank', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/reviews_per_bank.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Rating Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Overall rating distribution\n",
    "ax1 = axes[0]\n",
    "rating_counts = processed_df['rating'].value_counts().sort_index()\n",
    "colors = ['#d73027', '#fc8d59', '#fee08b', '#d9ef8b', '#91cf60']  # Red to Green\n",
    "bars = ax1.bar(rating_counts.index, rating_counts.values, color=colors, edgecolor='black')\n",
    "\n",
    "for bar, count in zip(bars, rating_counts.values):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 5,\n",
    "             str(count), ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "ax1.set_xlabel('Rating (Stars)', fontsize=12)\n",
    "ax1.set_ylabel('Number of Reviews', fontsize=12)\n",
    "ax1.set_title('Overall Rating Distribution', fontsize=14, fontweight='bold')\n",
    "ax1.set_xticks([1, 2, 3, 4, 5])\n",
    "\n",
    "# Rating distribution by bank\n",
    "ax2 = axes[1]\n",
    "rating_by_bank = processed_df.groupby(['bank_name', 'rating']).size().unstack(fill_value=0)\n",
    "rating_by_bank.plot(kind='bar', ax=ax2, colormap='RdYlGn', edgecolor='black')\n",
    "\n",
    "ax2.set_xlabel('Bank', fontsize=12)\n",
    "ax2.set_ylabel('Number of Reviews', fontsize=12)\n",
    "ax2.set_title('Rating Distribution by Bank', fontsize=14, fontweight='bold')\n",
    "ax2.legend(title='Rating', bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/rating_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Average Rating by Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average ratings\n",
    "avg_ratings = processed_df.groupby('bank_name')['rating'].agg(['mean', 'std', 'count'])\n",
    "avg_ratings.columns = ['Average Rating', 'Std Dev', 'Review Count']\n",
    "avg_ratings = avg_ratings.round(2)\n",
    "\n",
    "print(\"Average Ratings by Bank\")\n",
    "print(\"=\" * 50)\n",
    "print(avg_ratings)\n",
    "\n",
    "# Visualization\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "banks = avg_ratings.index\n",
    "means = avg_ratings['Average Rating']\n",
    "stds = avg_ratings['Std Dev']\n",
    "\n",
    "colors = sns.color_palette('Set2', len(banks))\n",
    "bars = ax.bar(banks, means, yerr=stds, capsize=5, color=colors, edgecolor='black')\n",
    "\n",
    "for bar, mean in zip(bars, means):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
    "            f'{mean:.2f}', ha='center', va='bottom', fontweight='bold', fontsize=12)\n",
    "\n",
    "ax.set_xlabel('Bank', fontsize=12)\n",
    "ax.set_ylabel('Average Rating', fontsize=12)\n",
    "ax.set_title('Average Rating by Bank (with Std Dev)', fontsize=14, fontweight='bold')\n",
    "ax.set_ylim(0, 5.5)\n",
    "ax.axhline(y=3, color='gray', linestyle='--', alpha=0.5, label='Neutral (3.0)')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/average_rating_by_bank.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Review Text Length Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Text length distribution\n",
    "ax1 = axes[0]\n",
    "processed_df['text_length'].hist(bins=50, ax=ax1, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "ax1.axvline(processed_df['text_length'].median(), color='red', linestyle='--', \n",
    "            label=f'Median: {processed_df[\"text_length\"].median():.0f}')\n",
    "ax1.axvline(processed_df['text_length'].mean(), color='orange', linestyle='--',\n",
    "            label=f'Mean: {processed_df[\"text_length\"].mean():.0f}')\n",
    "ax1.set_xlabel('Review Length (characters)', fontsize=12)\n",
    "ax1.set_ylabel('Frequency', fontsize=12)\n",
    "ax1.set_title('Distribution of Review Text Length', fontsize=14, fontweight='bold')\n",
    "ax1.legend()\n",
    "\n",
    "# Text length by bank (boxplot)\n",
    "ax2 = axes[1]\n",
    "processed_df.boxplot(column='text_length', by='bank_name', ax=ax2)\n",
    "ax2.set_xlabel('Bank', fontsize=12)\n",
    "ax2.set_ylabel('Review Length (characters)', fontsize=12)\n",
    "ax2.set_title('Review Length by Bank', fontsize=14, fontweight='bold')\n",
    "plt.suptitle('')  # Remove automatic title\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/text_length_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Reviews Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert review_date to datetime if needed\n",
    "processed_df['review_date'] = pd.to_datetime(processed_df['review_date'])\n",
    "\n",
    "# Reviews over time (monthly)\n",
    "processed_df['year_month'] = processed_df['review_date'].dt.to_period('M')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "for bank in processed_df['bank_name'].unique():\n",
    "    bank_data = processed_df[processed_df['bank_name'] == bank]\n",
    "    monthly_counts = bank_data.groupby('year_month').size()\n",
    "    ax.plot(monthly_counts.index.astype(str), monthly_counts.values, marker='o', label=bank, linewidth=2)\n",
    "\n",
    "ax.set_xlabel('Month', fontsize=12)\n",
    "ax.set_ylabel('Number of Reviews', fontsize=12)\n",
    "ax.set_title('Reviews Over Time by Bank', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Show only every nth label to avoid crowding\n",
    "n = max(1, len(ax.get_xticklabels()) // 10)\n",
    "for i, label in enumerate(ax.get_xticklabels()):\n",
    "    if i % n != 0:\n",
    "        label.set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/processed/reviews_over_time.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Sample Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample reviews for each bank\n",
    "for bank in processed_df['bank_name'].unique():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{bank}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    bank_df = processed_df[processed_df['bank_name'] == bank]\n",
    "    \n",
    "    # Show one positive and one negative review\n",
    "    positive = bank_df[bank_df['rating'] >= 4].head(1)\n",
    "    negative = bank_df[bank_df['rating'] <= 2].head(1)\n",
    "    \n",
    "    if not positive.empty:\n",
    "        print(f\"\\n[Positive Review - {positive['rating'].values[0]} stars]\")\n",
    "        print(f\"\\\"{positive['review_text'].values[0][:300]}...\\\"\")\n",
    "    \n",
    "    if not negative.empty:\n",
    "        print(f\"\\n[Negative Review - {negative['rating'].values[0]} stars]\")\n",
    "        print(f\"\\\"{negative['review_text'].values[0][:300]}...\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Data Export Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"Task 1 Completion Summary\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nData Collection:\")\n",
    "print(f\"  - Source: Google Play Store\")\n",
    "print(f\"  - Banks: {', '.join(BANK_NAMES.values())}\")\n",
    "print(f\"  - Total reviews: {len(processed_df)}\")\n",
    "\n",
    "print(f\"\\nData Quality:\")\n",
    "print(f\"  - Missing values: {processed_df.isnull().sum().sum()}\")\n",
    "print(f\"  - Duplicates: {processed_df.duplicated().sum()}\")\n",
    "print(f\"  - Date range: {processed_df['review_date'].min()} to {processed_df['review_date'].max()}\")\n",
    "\n",
    "print(f\"\\nOutput Files:\")\n",
    "print(f\"  - Raw data: {DATA_PATHS['raw_reviews']}\")\n",
    "print(f\"  - Processed data: {DATA_PATHS['processed_reviews']}\")\n",
    "\n",
    "print(f\"\\nColumns in processed dataset:\")\n",
    "for col in processed_df.columns:\n",
    "    print(f\"  - {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final dataset preview\n",
    "processed_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Next Steps\n",
    "\n",
    "With Task 1 complete, we have:\n",
    "- ✅ Scraped 400+ reviews per bank from Google Play Store\n",
    "- ✅ Preprocessed and cleaned the data\n",
    "- ✅ Normalized dates to YYYY-MM-DD format\n",
    "- ✅ Filtered to English-only reviews\n",
    "- ✅ Saved clean CSV with required columns\n",
    "\n",
    "**Task 2** will involve:\n",
    "- Sentiment analysis using DistilBERT\n",
    "- Thematic analysis with keyword extraction\n",
    "- Topic clustering (3-5 themes per bank)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
